\begin{multicols}{2}
[
\subsection{Example Training Configuration File}\label{appendix:ppo-trainer}
% All human things are subject to decay. And when fate summons, Monarchs must obey.
]
\begin{minted}[
    gobble=4,
    frame=single,
    linenos
  ]{yaml}
    # config file: run63++100.yaml
    behaviors:
      Drone:
        trainer_type: ppo
        hyperparameters:
          batch_size: 1024
          buffer_size: 10240
          learning_rate: 0.0003
          beta: 0.01
          epsilon: 0.2
          lambd: 0.95
          num_epoch: 3
          learning_rate_schedule: linear
        network_settings:
          normalize: false
          hidden_units: 256
          num_layers: 2
          vis_encode_type: simple
          # no lstm
        reward_signals:
          extrinsic:
            gamma: 0.99
            strength: 1.0
          curiosity:
            gamma: 0.99
            strength: 0.02
            network_settings:
              hidden_units: 256
            learning_rate: 0.0003
        keep_checkpoints: 5
        max_steps: 20000000
        time_horizon: 64
        summary_freq: 30000
\end{minted}
\columnbreak

\begin{minted}[
    gobble=4,
    frame=single,
    % linenos
  ]{yaml}
    environment_parameters:
      # 0:base, 1:open, 2:fire, 3:forest
      EnvironmentType: 0 
      steuernModus: 1
      m_EnableVFX: 0
      m_EnableTrainDebuggingLogs: 0
      # base
      m_TrainMovingForward: 1
      m_TrainTargetSpeed: 1
      # octree
      leafNodeSize: 4
      m_AddOctreeObservations: 0
      m_TrainOctreeDiscovery: 0
      m_TrainLingerPolicy: 0
      m_AddPigeonObservations: 0
      # voxel
      m_TrainVoxelCollection: 1
      allowedToSeeVoxels: 1
      m_VoxelRewardStrength: 1
      NormalizeVoxelReward: 0 
      # enabled for all voxel-behaviors
      m_SpeedSensitivityToTargetsInFOV: 1
      # shortest
      m_AddShortestPathObservations: 0
      m_TrainShortestPath: 0
      # detector
      m_LoadDetector: 0
      m_AddDetectorObservations: 0
      m_TrainObjectDetectionMaximization: 0
      NormalizeDetectionsReward: 1
      # curiosity
      m_AddSemanticCuriosityObservations: 0
      m_TrainSemanticCuriosity: 0
      # entropy
      m_AddSemanticEntropyObservations: 0
      m_TrainSemanticEntropy: 0
\end{minted}

\end{multicols}
