
\chapter{Results}\label{chap:4}
% \section{Prototyping/Evaluating the System}
% 5-7 pages
% \lipsum[1]\todo{TODO}


    
This chapter will provide an overview of the achieved results, the determined baselines, the setup of the experiments, the nature of the environment and the experiment process to solve the posed research question. 
This chapter also adapts the structure for machine learning algorithms proposed by \textcite{luckert2016using}.
%  the pipeline deployment details,  collection and labelling steps, the neural network implementation and training. Finally, the pose estimation algorithms and the pipeline are evaluated.
Section \ref{chap:4:setup} illustrates the environment and sensors setup, 
section \ref{chap:4:behaviors} describes the exploration and voxel-curious behaviors setup, 
% section \ref{chap:4:train_data} explains the data collection and neural network training, 
% section \ref{chap:4:\ref{chap:4:training}} detailing the training , 
and section \ref{chap:4:results} presents the experiment results. The following questions will be answered thoroughly:
\begin{itemize}
    \item How were the experiments set up?
    % \item What was the cloud deployment setup for the solution?
    \item How many episodes, metrics, etc., were ran and collected for training, testing and optimizing the algorithms?
    % \item Which tools were used to acquire the metrics, create the data and perform the experiments?
    \item Which algorithm parameters were the most influential?
    % \item Which algorithm optimizations were done?
    \item What were the achieved results on each experiment?
    \item What was the setup of the best performing algorithm?
    % \item Which algorithm optimizations were done?
\end{itemize}

As we approach the presentation of our results, it is important to step back for a moment to look at our approach from two perspectives. The initial presented perspective looks at the problem as an object uncertainty problem, where our interest is to look at objects from multiple perspectives to reduce our \textit{uninformativeness} about them. To this end, we proposed a reinforcement learning agent that explores environments to find such objects of interest.
However, the second perspective for our proposed method is a navigation perspective, which was implicitly presented through our related works. As mentioned before, visual navigation solutions can be categorized depending if the location of the goal is known or unknown \cite{chaplot2020semantic}. Among these, the commonly studied point-to-goal task presents two fallacies
\begin{itemize}
    \item the location of the goal is known (either implicitly through a path or explicitly through coordinates), which is not the case in, for example, rescue missions.
    \item the goal is not situated very far from the target (exhaustive exploration is not required), which conceals the real exploratory performance of embodied algorithms.
\end{itemize}

Not only do traditional navigation approaches depend on map awareness, to subsequently execute some sort of path-planning algorithm, but real life problems such as rescue scenarios or dynamic environments, provide the agent with limited, changing, partial observability of the environment. This has laid the path for mapless solutions to take over classical navigation approaches \cite{brandenburger2021mapless, xie2020snapnav, pfeiffer2018reinforced}. Our approach takes this into consideration to account for the partial observability in an unknown environment, where the location of goals are also unspecified.

Moreover, traditional approaches subdivide the navigation problem into sub-modules for obstacle avoidance, map creation and then path planning. Accordingly, newer approaches avoid the pitfalls of traditional, complex model-based approach which attempt to model the dynamics of the real world and carry some sort of bias. They also solutions leverage deep learning methods to provide end-to-end solutions to the navigation problem \cite{wang2018look, pfeiffer2018reinforced}. We therefore proposed a model-free method that leverages neural networks and that is capable of adapting across environments.  

All of these methods, however, usually depend on the quality of the sensorial data obtained to reconstruct the world to be navigated.
Dense mapping systems are usually victims of noise, outliers and missing data, and must even balance runtime performance and reconstruction quality. Moreover, these methods either ignore moving targets or use expensive raycast operations to construct maps of the dynamic objects in the scene. \cite{weder2020routedfusion, pfeiffer2018reinforced, grinvald2021tsdf} % of surfel clouds or TSDF Volumes 
This is the pinnacle for this thesis, where we propose the usage of voxels to provide our agent with robustness to outliers, noise and missing data, and octrees for the efficient, mapless, exploration of changing environments. 
Furthermore, we take inspiration from the physiology of pigeons' biological compass to provide our agent with a mapless technique to orient itself in unknown environments.
% , achieving 100% coverage of open world scene

Finally, as mentioned before, given the increasing momentum of reconstruction methods and synthetic data to fuel other machine learning pipelines \cite{yu2021plenoxels, nvidia2021synthetic}, we decided to exploit Unity 3D to train and test our agent in multiple 3D environments. This allows direct portability and extensibility of our agent to new methods, new scenarios, further benchmarks, etc. 
Without further delay, the following sections present the the training and the DARPA test results.
% of the DARPA test environments.


% As presented in Section \ref{chap:3:further-use:evaluation-framework}, we test agents on 3D environments inspired by the DARPA-subterreanean challenge \cite{DARPA}, our method achieves a better performance by at least a factor of 2 in time-to-discovery in an open world environment of 160 m2, compared to our implementations of model-free shortest path methods, object-detector-based methods and semantic-curiosity-based methods. Where traditional methods achieve either navigation or trajectory planning around objects, our agent achieves model-free exploration of both objects and environments using efficient data structures in a mapless fashion.

% This, along the lines of 

% Our approach converges these two stories, since 
% It is of special interest to demonstrate that larger environments reveal weaker policies. Several works in navigation 

% different performance, as 




% \newpage

\section{Results}\label{chap:4:results}
This section presents the results of the experiments. Section \ref{chap:4:results-RQ2} deals with the results concerning the exploration of objects and \ref{chap:4:results-RQ1} deals with the results concerning the exploration of unknown spaces using octrees. Each subsection will present the best results obtained on the exploration policy variants and a brief description of the most representative details of each variant.

% • How can an embodied agent increase the overall certainty about an object’s characteristics, i.e., how
% can trajectories around objects of interest be generated to reduce the uncertainty about such objects?
% • How can these objects be found in large and unknown environments by the same agent

\subsection{Research Question 1}\label{chap:4:results-RQ1}

The first research question focuses on the reduction of uncertainty about objects, which we have posed as a voxel-curiosity task. Below, the best results for each voxel-curious variant are be presented in two subsections according to if the model has knowledge of voxels. 
It is worth mentioning that the training environment provided the agent 6 goals per episode situated at a distance of 5-50 meters away from the origin. 
In contrast, the DARPA testing environment contained a single goal located between 30 to 50 meters away from the origin. This sparse-reward testing environment evaluates the actual explorative capabilities of an agent.
For information on the run names, please refer to the previous Section \ref{chap:4:behaviors} and Appendix \ref{appendix:agents_explanations}.


% \newpage

\subsubsection{Agents with Knowledge of Voxels}
The following Table \ref{tab:RQ1-results} shows a brief overview of the results at the top 50 percentile based on the average amount of objects scanned. More information about all methods are presented in the tables afterwards.
\begin{longtable}{|l|c|c|c|}                            \hline %c|
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}            
    & \theadcentered{Episode Length \%}                
    & \theadcentered{Average Total \\ Objects Scanned} 
    & \theadcentered{Standard \\ Deviation} 
    \\ \hline
    % & \thead{Standard Deviation}            \\ \hline
    % run61-voxel	&	100	\%	&	0.34	&	0.10	\\ \hline
    % run61-voxel-constrained	&	100	\%	&	0.33	&	0.11	\\ \hline
    % run63++025	&	89	\%	&	1.56	&	0.24	\\ \hline
    % run63++050	&	94	\%	&	1.05	&	0.20	\\ \hline
    % run63++075	&	71	\%	&	0.96	&	0.17	\\ \hline
    % run63++100	&	99	\%	&	0.77	&	0.17	\\ \hline
    % run63++100-nospeed	&	97	\%	&	1.52	&	0.20	\\ \hline
    % run63++100-nospeed-nolinger	&	98	\%	&	1.73	&	0.21	\\ \hline
    % run63-normalized	&	97	\%	&	0.40	&	0.22	\\ \hline
voxel++025 & 94 & {\cellcolor[HTML]{B6D8D1}} \color[HTML]{000000} 1.56 &                         0.22 \\ \hline
voxel++100-nospeed & 98 & {\cellcolor[HTML]{BEDCD6}} \color[HTML]{000000} 1.52 &                         0.24 \\ \hline
voxel++100-nospeed-nolinger & 97 & {\cellcolor[HTML]{98CAC0}} \color[HTML]{000000} 1.73 &                        0.20 \\ \hline
voxel++100-nospeed-nolinger-oracle & 96 & {\cellcolor[HTML]{E0EDEA}} \color[HTML]{000000} 1.33 &                         0.20 \\ \hline
voxel++100-nospeed-nolinger-oracle-8 & 99 & {\cellcolor[HTML]{90C6BB}} \color[HTML]{000000} 1.77 &                       0.21 \\ \hline
voxel++100-nospeed-nolinger-pigeon-oracle-8 & 97 & {\cellcolor[HTML]{E6F0EE}} \color[HTML]{000000} 1.30 &                        0.24 \\ \hline
voxel++100-nospeed-oracle-4 & 100 & {\cellcolor[HTML]{A9D2CA}} \color[HTML]{000000} 1.64 &                       0.19 \\ \hline
voxel++100-nospeed-oracle-8-pigeon & 93 & {\cellcolor[HTML]{A1CFC5}} \color[HTML]{000000} 1.68 &                         0.23 \\ \hline
object-detector-pure-vision & 99 & {\cellcolor[HTML]{BADBD4}} \color[HTML]{000000} 1.54 &                        0.19 \\ \hline
voxel-entropy++100-nospeed & 97 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2.10 &                         0.20 \\ \hline
voxel-entropy++100-oracle & 96 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 1.27 &                          0.20 \\ \hline
voxel-entropy++100-oracle-nospeed & 98 & {\cellcolor[HTML]{B1D6CE}} \color[HTML]{000000} 1.59 &                          0.20 \\ \hline




% readable\_name & \%episode\_length & avg\_total\_objects\_scanned \\ \hline
% voxel & 100 
% voxel++025 & 43 
% voxel++050 & 76 
% voxel++100-nospeed & 22 
% voxel++100-nospeed-nolinger & 22 
% voxel++100-nospeed-nolinger-oracle-8 & 7 
% voxel++100-nospeed-oracle-4 & 5 
% voxel++100-nospeed-oracle-8-pigeon & 54 
% object-detector-pure-vision & 12 
% voxel-entropy++100 & 54 
% voxel-entropy++100-nospeed & 25 
% voxel-entropy++100-oracle-nospeed & 16 
    \caption{Overview of the best object-focused runs with knowledge of voxels respect to the \textit{Episode Length} and the \textit{Total Objects Scanned} metrics. A small episode length indicates that the agent is overwhelmed by the penalties and the fastest way to minimize the reward function is to end the episode. An object is marked as scanned once all voxels that belong to it are scanned by the agent.
    } \label{tab:RQ1-results}
\end{longtable}

\subsubsection{Agents without Knowledge of Voxels}
The following Table \ref{tab:RQ1-results-noknowledgeofvoxels} presents the aggregated results for the agents that get rewarded for finding voxels but are not able to see them in the grid sensor view. These agents must rely on their other information to find objects and their voxels, such as shortest path angles (look angle and walk angle), the output of an object detector, the temporal semantic map in their trajectories \cite{chaplot2020semantic}, the semantic entropy in the environment, or no information at all (blind agent).
% is shown below in Table , which also shows the general performance of the algorithms for the voxel scanning task.

\begin{longtable}{|l|c|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}           
    & \theadcentered{Episode \\ Length \%}                
    & \theadcentered{Average Total \\ Objects Scanned}
    & \theadcentered{Standard \\ Deviation} 
    & \theadcentered{otal \\ Detections Count}
    % & \thead{Standard Deviation}    \\ 
    \hline
    random-agent	&	89	\%	& {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000}	0.14    &  0.15  &    {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 10221.18	\\ \hline % 	&	0.24
shortest-path & 97 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.06 &         0.04 &       {\cellcolor[HTML]{90C7BC}} \color[HTML]{000000} 387956.37 \\ \hline
semantic-curiosity & 99 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.07 &        0.05 &          {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 831982.04 \\ \hline
semantic-entropy &  {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000}  40 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.13 &      0.17 &        {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 217608.01 \\ \hline
blind-agent-voxel-constrained & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.33 &        0.11 &         {\cellcolor[HTML]{90C7BC}} \color[HTML]{000000} 350545.99 \\ \hline
blind-agent-voxel & 99 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.34 &         0.10 &       {\cellcolor[HTML]{99CBC1}} \color[HTML]{000000} 452437.65 \\ \hline
object-detector & 97 & {\cellcolor[HTML]{E5EFED}} \color[HTML]{000000} 0.39 &       0.33 &        {\cellcolor[HTML]{79BCAE}} \color[HTML]{000000} 627828.14 \\ \hline
object-detector-nospeed & 93 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 1.01 &       0.25 &        {\cellcolor[HTML]{9DCDC3}} \color[HTML]{000000} 433438.51 \\ \hline


    \caption{Overview of the best object-focused runs without knowledge of voxels.
    % with respect to the \textit{Episode Length} and the \textit{Total Objects Scanned} metrics}. 
    }
    \label{tab:RQ1-results-noknowledgeofvoxels}
\end{longtable}

More detailed tables of voxel-aware agents can be found in Appendix \ref{appendix:RQ1-results-noknowledgeofvoxels}.







\subsection{Research Question 2}\label{chap:4:results-RQ2}

This section deals with the results related to question 2, which focuses on the exploration coverage of a 3D space given octrees as the 3D data structure for the space. 
The first two tables present these results through the octree discovery reward.

%  8000, 800 and 200 nodes
Table \ref{tab:RQ2-results} summarizes the results for the agents that are aware of octrees for the given task. This can be through feedback of how many nodes were discovered each timestep or through pigeon observations. 
%  using the octree discovery reward

% The presented numbers are the result of 500000 optimizations 
\begin{longtable}{|l|c|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \textbf{Method}            
    & \theadcentered{Episode \\ Length \%}          
    & \theadcentered{Octree Leaf \\ Nodes Visited} 
    & \theadcentered{Octree Leaf \\ Nodes Visited \%} 
    & \theadcentered{Visited  \\ Volume  ($m^3$)} 
    % & \theadcentered{Standard \\ Deviation} 
    % & \thead{Octree Discovery Reward}                
    % & \thead{Standard Deviation}            
    \\ \hline
    % run61-explore	&	95	\%	&	0.89	&	0.07	\\ \hline
    % run61-explore-constrained	&	100	\%	&	0.93	&	0.03	\\ \hline
  
    
    octree-4 & 92 & 87.16 & 2.18 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 348.64 \\ \hline
    octree-4-pigeon & 17 & 10.20 & 2.04 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 81.57 \\ \hline
    octree-4-pigeon-pathak & 22 & 12.32 & 2.46 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 98.52 \\ \hline
    octree-8 & 43 & 22.90 & 4.58 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 183.19 \\ \hline
    octree-16 & 4 & 1.69 & 2.71 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 27.08 \\ \hline
    octree-16-constrained & 100 & 12.70 & 20.32 & {\cellcolor[HTML]{DDEBE8}} \color[HTML]{000000} 203.16 \\ \hline
    octree-16-constrained-pigeon & 100 & 20.35 & 32.56 & {\cellcolor[HTML]{6AB4A5}} \color[HTML]{000000} 325.61 \\ \hline
    octree-16-constrained-pigeon-pathak & 100 & 6.07 & 9.71 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 97.06 \\ \hline
    
    \caption{Overview of the environment-exploration focused runs with knowledge of octrees. 
    % These results are with respect to the \textit{Episode Length} and the \textit{Octree Discovery Reward} metrics}.
    }
    \label{tab:RQ2-results}
\end{longtable}


Pathak's method \cite{pathak2017curiosity} usage is two-fold. First, without knowledge of octrees, it is used as one baseline to compare the exploration performance to our method. Secondly, it is also used as a curiosity module for other agents, as suggested by Unity ML-Agents \cite{github-unity-mlagents-toolkit}, given that it motivates the agent to prefer newer states.



The results for the environment-focused methods that have no knowledge of octrees are presented below in Table \ref{tab:RQ2-results-noknowledgeofOctrees}.
\begin{longtable}{|l|c|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \textbf{Method}            
    & \theadcentered{Episode \\ Length \%}          
    & \theadcentered{Octree Leaf \\ Nodes Visited} 
    & \theadcentered{Octree Leaf \\ Nodes Visited \%} 
    & \theadcentered{Visited  \\ Volume  ($m^3$)} 

    % & \thead{Octree Discovery Reward}                
    % & \thead{Standard Deviation}       
    \\ \hline
    % run61-explore	&	95	\%	&	0.89	&	0.07	\\ \hline
    random-agent	&	100	& 0.01 & 0	& {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000}	0.04	\\ \hline
    blind-octree-explorer & 91 & 86.40 & 2.16 & {\cellcolor[HTML]{77BAAD}} \color[HTML]{000000} 345.62 \\ \hline
    blind-octree-explorer-nospeed & 95 & 91.82 & 2.30 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 367.29 \\ \hline
    blind-octree-explorer-nospeed-pathak & 91 & 88.52 & 2.21 & {\cellcolor[HTML]{6AB4A5}} \color[HTML]{000000} 354.09 \\ \hline
    
    pathak-4 & 90 & 79.74 & 1.99 & {\cellcolor[HTML]{A1CFC5}} \color[HTML]{000000} 318.97 \\ \hline
    pathak-8 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 65 & 30.48 & 6.10 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 243.85 \\ \hline
    pathak-16 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 4 & 1.66 & 2.66 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 26.63 \\ \hline
    pathak-16-constr-nospeed & 100 & 1.01 & 1.62 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 16.19 \\ \hline
    pathak-16-constr-nospeed-nolinger & 100 & 19.05 & 30.48 & {\cellcolor[HTML]{B7D9D2}} \color[HTML]{000000} 304.76 \\ \hline
    
    \caption{Overview of the environment-exploration focused agents that have no knowledge of octrees. 
    % These results are with respect to the \textit{Episode Length} and the \textit{Octree Discovery Reward} metrics
    }
    \label{tab:RQ2-results-noknowledgeofOctrees}
\end{longtable}


% The contrast in explorative performance for the best octree exploration methods and the best voxel-curious methods is presented below in
 The performances can be contrasted based on the number of scan nodes, which originate from objects of interest or obstacles (stones) in the environment, the number of leaf nodes and the lingering behavior. 
The 160$m^2$ environment consists of 40, 20, 10 octree nodes on the XZ-axis when segmented with node sizes of 4$m^3$, 8$m^3$ and 16$m^3$, respectively. Since the vertical space is not useful for our use case (objects are not situated at different heights), the Y-axis is limited to 5, 2.5 and 1.25 nodes, respectively. This is equal to 3D volumes of 4000, 500 and 62.5 nodes, respectively.

Table \ref{appendix:RQ1-results-octreeFocusedRuns} presents more details for the results for all environment-focused agents. More details can be found in Appendix \ref{appendix:results-mixed-focused-agents-bigtable}.
% Table \ref{tab:RQ2-results-comparative-voxeloctree} presents the results for all environment-focused agents.

\newpage



\subsection{Mixed-Focus Agents}
This sections presents the variant of agents that have both knowledge of the environment and voxels. Information about the environment can be present in the form of octree nodes or \textit{pigeon observations}. 
We propose an adapted F1-score \cite{f1score2022} to calculate the harmony mean between the total scanned objects and the visited volume. This provides a way to evaluate agents based on their performance on both tasks using only one statistic. 
% \newpage
The following Table \ref{tab:results-mixed-agents} displays the results for the mixed-focus agents with their respective episode length, average amount of scanned objects, F1-score and percentage of octree leaf nodes visited.


\begin{longtable}{|l|c|c|c|c|}                            \hline

\theadcenteredLeft{Method}
& \theadcentered{Episode \\ Length \%}
& \theadcentered{Total Objects \\ Scanned}
& \theadcentered{F1-score}
& \theadcentered{Visited  \\ Volume  ($m^3$)} 

% & \theadcentered{Octree Leaf \\ Nodes Visited \%}
\\ \hline

explorer-entropy-4 & 97 & {\cellcolor[HTML]{CDE4DF}} \color[HTML]{000000} 0.54 & {\cellcolor[HTML]{C6E0DB}} \color[HTML]{000000} 0.21 & {\cellcolor[HTML]{69B4A5}} \color[HTML]{000000} 310.53 \\ \hline
explorer-entropy-4-nolinger-noTrainEntropy & 97 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.17 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.08 & {\cellcolor[HTML]{75B9AB}} \color[HTML]{000000} 281.55 \\ \hline
explorer-entropy-4-noTrainEntropy & 98 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 358.06 \\ \hline
explorer-entropy-8 & 88 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 1.96 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 0.30 & {\cellcolor[HTML]{ACD4CC}} \color[HTML]{000000} 151.04 \\ \hline
explorer-entropy-8-nolinger & 96 & {\cellcolor[HTML]{65B2A2}} \color[HTML]{000000} 1.77 & {\cellcolor[HTML]{9CCCC2}} \color[HTML]{000000} 0.24 & {\cellcolor[HTML]{BADAD4}} \color[HTML]{000000} 117.86 \\ \hline
explorer-entropy-8-nolinger-noTrainEntropy & 98 & {\cellcolor[HTML]{60AFA0}} \color[HTML]{000000} 1.83 & {\cellcolor[HTML]{94C8BE}} \color[HTML]{000000} 0.25 & {\cellcolor[HTML]{B8DAD3}} \color[HTML]{000000} 120.73 \\ \hline
explorer-entropy-8-noTrainEntropy & 92 & {\cellcolor[HTML]{6FB6A8}} \color[HTML]{000000} 1.65 & {\cellcolor[HTML]{7CBDB0}} \color[HTML]{000000} 0.27 & {\cellcolor[HTML]{B1D6CE}} \color[HTML]{000000} 139.49 \\ \hline
explorer-entropy-16 & 95 & {\cellcolor[HTML]{E8F1EF}} \color[HTML]{000000} 0.22 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.05 & {\cellcolor[HTML]{DEECE9}} \color[HTML]{000000} 31.36 \\ \hline
explorer-entropy-16-nolinger & 100 & {\cellcolor[HTML]{B9DAD3}} \color[HTML]{000000} 0.78 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.14 & {\cellcolor[HTML]{CCE3DE}} \color[HTML]{000000} 74.64 \\ \hline
explorer-entropy-16-nolinger-noTrainEntropy & 97 & {\cellcolor[HTML]{97CABF}} \color[HTML]{000000} 1.18 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.16 & {\cellcolor[HTML]{CAE2DD}} \color[HTML]{000000} 79.76 \\ \hline
explorer-entropy-16-noTrainEntropy & 99 & {\cellcolor[HTML]{E7F0EE}} \color[HTML]{000000} 0.23 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.05 & {\cellcolor[HTML]{DEECE9}} \color[HTML]{000000} 32.13 \\ \hline

    \caption{Brief overview of the mixed-focused runs, with respect to the \textit{Total Objects Scanned}, \textit{F1-score} and \textit{Leaf Nodes Visited}.}
    \label{tab:results-mixed-agents}
\end{longtable}

% More details related to these agents can be found in Appendix \ref{appendix:results-mixed-focused-agents-bigtable}.


% \newpage


\section{Evaluation Framework}
This section presents the performance of the best performing agents that reached the \textit{DARPA} evaluation challenge presented in Section \ref{chap:3:further-use:evaluation-framework}. 
These are done in the DARPA evaluation scenarios, where they test
\begin{itemize}
    \item how good the agent is at finding objects and fully exploring them (abbr: obj-goal).
    \item how good the agent is at maximizing octree exploration coverage (abbr: env-goal).
\end{itemize}

% 
% As shown by , agents are categorized in: 

% (such as the shortest-path agent, object detector agent, etc.).
% : object-focused runs, environment-focused runs, mixed-focused runs, baselines. The chosen candidates for the test environments 
To this end, the evaluation candidates that were selected from each agent category presented in Figure \ref{fig:darpa-bracket} are shown the following Table \ref{tab:results-darpa-candidates}. 
% \begin{itemize}
%     \item object-focused runs
%     \item environment-focused runs
%     \item mixed-focused runs
%     \item baselines (such as the shortest-path agent, object detector agent, etc.)
% \end{itemize}

% that serve as baselines to compare the performance of our proposed method. These baselines were also trained under different parameter
%  configurations to reach the best performant one, as displayed in Table with the metrics collected and the baselines used to evaluate our method 
% The baselines were setup using


% \newpage


\begin{longtable}{|l|c|c|c|c|}                            \hline
    \theadcenteredLeft{Method}            
    % & \theadcentered{Candidate for \\ Objects-Test}  
    % & \theadcentered{Candidate for \\ Environment-Test}  
    & \theadcentered{F1-score}        
    & \theadcentered{Total Objects \\ Scanned}
    & \theadcentered{Visited  \\ Volume  ($m^3$)} 
    & \theadcentered{DARPA \\ Scenario} 
    \\ \hline
        
    % blind-octree-explorer-nospeed & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 367.29 &                                  {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}    env-goal \\ \hline
    % octree-16-constrained & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{98CAC0}} \color[HTML]{000000} 203.16 &                                          {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}    env-goal \\ \hline
    % octree-16-constrained-pigeon & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{66B2A3}} \color[HTML]{F1F1F1} 325.61 &                                   {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline
    % octree-4 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{5CAD9D}} \color[HTML]{F1F1F1} 348.64 &                                                       {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline
    % % octree-16-constrained-pigeon-nospeed            & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00        & & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00       \\ \hline

    % voxel++025 & {\cellcolor[HTML]{75B9AB}} \color[HTML]{000000} 0.26 & {\cellcolor[HTML]{89C3B7}} \color[HTML]{000000} 1.43 & {\cellcolor[HTML]{AED5CD}} \color[HTML]{000000} 150.49 &                             {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} both \\ \hline
    % voxel++100-nospeed & {\cellcolor[HTML]{78BBAD}} \color[HTML]{000000} 0.25 & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 1.47 & {\cellcolor[HTML]{B0D6CE}} \color[HTML]{000000} 144.93 &                     {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
    % voxel++100-nospeed-nolinger & {\cellcolor[HTML]{77BAAD}} \color[HTML]{000000} 0.25 & {\cellcolor[HTML]{79BCAE}} \color[HTML]{000000} 1.62 & {\cellcolor[HTML]{B3D7CF}} \color[HTML]{000000} 138.43 &            {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline

    % voxel++100-nospeed-oracle-8-pigeon & {\cellcolor[HTML]{7BBCAF}} \color[HTML]{000000} 0.25 & {\cellcolor[HTML]{7DBDB0}} \color[HTML]{000000} 1.57 & {\cellcolor[HTML]{B3D7D0}} \color[HTML]{000000} 137.12 &              {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
    % shortest-path & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.02 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.06 & {\cellcolor[HTML]{D1E6E1}} \color[HTML]{000000} 63.70 &                                    {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
    % object-detector-pure & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 0.18 & {\cellcolor[HTML]{AED5CD}} \color[HTML]{000000} 0.94 & {\cellcolor[HTML]{BEDDD6}} \color[HTML]{000000} 110.38 &                            {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
    % semantic-curiosity & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.02 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.06 & {\cellcolor[HTML]{D5E8E4}} \color[HTML]{000000} 54.12 &                               {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}     env-goal \\ \hline
    % semantic-entropy & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.05 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.13 & {\cellcolor[HTML]{D1E6E1}} \color[HTML]{000000} 63.50 &                                 {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
    % voxel-entropy++100-nospeed & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 0.29 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2.10 & {\cellcolor[HTML]{AFD5CD}} \color[HTML]{000000} 147.69 &                      {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}     env-goal \\ \hline
    % explorer-entropy-8 & {\cellcolor[HTML]{56AB9A}} \color[HTML]{F1F1F1} 0.29 & {\cellcolor[HTML]{5FAF9F}} \color[HTML]{F1F1F1} 1.96 & {\cellcolor[HTML]{ADD4CC}} \color[HTML]{000000} 151.04 &                     {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} both \\ \hline
    % explorer-entropy-16 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.05 & {\cellcolor[HTML]{E5EFED}} \color[HTML]{000000} 0.22 & {\cellcolor[HTML]{DFECE9}} \color[HTML]{000000} 31.36 &                              {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline


{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         blind-octree-explorer-constrained-nospeed & 0.00 & 0.00 & 367.29 &      {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}    env-goal \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         octree-16-constrained & 0.00 & 0.00 & 203.16 &              {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}    env-goal \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         octree-16-constrained-pigeon & 0.00 & 0.00 & 325.61 &       {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         octree-4 & 0.00 & 0.00 & 348.64 &                           {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline
{\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000}         voxel++025 & 0.26 & 1.43 & 150.49 &                         {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} both \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         voxel++100-nospeed & 0.25 & 1.47 & 144.93 &                 {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         voxel++100-nospeed-nolinger & 0.25 & 1.62 & 138.43 &        {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         voxel++100-nospeed-oracle-8-pigeon & 0.25 & 1.57 & 137.12 & {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         shortest-path & 0.02 & 0.06 & 63.70 &                       {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         object-detector-pure & 0.18 & 0.94 & 110.38 &               {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         semantic-curiosity & 0.02 & 0.06 & 54.12 &                  {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}     env-goal \\ \hline
{\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000}         semantic-entropy & 0.05 & 0.13 & 63.50 &                    {\cellcolor[HTML]{C4D7B8}} \color[HTML]{000000} obj-goal \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         voxel-entropy++100-nospeed & 0.29 & 2.10 & 147.69 &         {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}     env-goal \\ \hline
{\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000}         explorer-entropy-16 & 0.05 & 0.22 & 31.36 &                 {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} both \\ \hline
{\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}         explorer-entropy-8 & 0.29 & 1.96 & 151.04 &                 {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}   env-goal \\ \hline

    % explorer-entropy-16
   
    % blind-agent-explore-constrained-nospeed             & -         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00       \\ \hline
    % octree-16-constrained                     & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00        \\ \hline
    % octree-16-constrained-pigeon                    & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00      \\ \hline
    % octree-16-constrained-pigeon-nospeed                   & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00       \\ \hline
    % octree-4                  & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00      \\ \hline
    % octree-4-constrained-pigeon-nospeed                  & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00     \\ \hline
    
    
    % voxel++025                              & {\cellcolor[HTML]{D2E6E2}} \color[HTML]{000000} 0.20   & {\cellcolor[HTML]{D2E6E2}} \color[HTML]{000000} 0.20        \\ \hline
    % voxel++100-nospeed                      & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 0.19   & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 0.19       \\ \hline
    % voxel++100-nospeed-nolinger             & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 0.19   & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 0.19        \\ \hline
    
    %                         % voxel++100-nospeed-oracle-8-pigeon  & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 0.44*   & -     \\ \hline
    
    % shortest-path                           &  {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.02      & -    \\ \hline
    % object-detector-pure                    & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.14       & -    \\ \hline
    % semantic-curiosity                      & -                                                          & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.02      \\ \hline
    % semantic-entropy                        & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.04       & -            \\ \hline
    % voxel-entropy++100-nospeed              & {\cellcolor[HTML]{D1E6E1}} \color[HTML]{000000} 0.20       & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.04     \\ \hline
    % explorer-entropy-8                      & {\cellcolor[HTML]{6BB4A6}} \color[HTML]{000000} 0.33      & {\cellcolor[HTML]{6BB4A6}} \color[HTML]{000000} 0.33  \\ \hline
    % explorer-entropy-16                     & -                                                         & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.09               \\ \hline
    %                     % explorer-entropy-16-nolinger                  &  {\cellcolor[HTML]{88C3B7}} \color[HTML]{000000} 0.28*   & -        \\ \hline
    %                     % explorer-entropy-16-nolinger-noTrainEntropy   & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 0.37*    & -         \\ \hline

  

    \caption{Best runs across all agent categories with their respective relevant metrics and the DARPA scenario in which they will be tested. For example, \textit{voxel++025} is tested in the object-exploration scenario. White letters represent the highest runs from their category.
    } % with their respective F1-scores. These F1-scores are allocated in the DARPA test environment in which the runs were evaluated.
    \label{tab:results-darpa-candidates}
\end{longtable}

\newpage

Given that the general performance of agents has already been registered during training (for both object and environment exploration), not all the best runs are candidates for both tests. 
Therefore, agents that have no motivation for voxels, such as \textit{octree-4}, are not included in the candidates for the {Object-Test}. Similarly, voxel-focused runs such as \textit{voxel++025} are not considered candidates for the Environment-Test.

% voxel++100-nospeed-oracle-8-pigeon
% \newpage
As mentioned before, one DARPA environment evaluates the object-explorative performance of the agent, by situating a goal randomly in the scene until the agent has collected 3 goals. The times to each goal and the seconds per meter are collected to evaluate how fast the agent reaches the goal. This also evaluates which run is the fastest to the first goal, and which one is the first one to reach the last goal. 
Table \ref{tab:results-evaluation-framework} displays the results for the voxel-goal task, with the different times to each three objects, and the average seconds per meter. As mentioned before, an object is marked as collected if all of its voxels are scanned.

Finally, each test is considered an episode, where each episode can run up to 40 thousand timesteps and a total of 7.5 million timesteps were tested. On the object exploration environment, a test (episode) is completed when all three goals were collected. On the octree exploration environment, the test is completed when 100\% of the environment was discovered.


\begin{longtable}{|l|c|c| c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}            
    & \theadcentered{Avg. Time \\ to Goal \#1} 
    & \theadcentered{Avg. Time \\ to Goal \#2}
    & \theadcentered{Avg. Time \\ to Goal \#3}
    & \theadcentered{Avg. Time \\ to Goal}
    & \theadcentered{Avg. s/m  \\ btw. Goals}
    % & \thead{Acc.s/m  \\ to Last Goal} 
    \\ \hline
    
    
    % voxel++025 & {\cellcolor[HTML]{C7E1DB}} \color[HTML]{000000} 244 &  -  &  -  & {\cellcolor[HTML]{C7E1DB}} \color[HTML]{000000} 244 & {\cellcolor[HTML]{84C1B4}} \color[HTML]{000000} 4 \\ \hline
    % voxel++100-nospeed & {\cellcolor[HTML]{96C9BF}} \color[HTML]{000000} 141 & {\cellcolor[HTML]{95C9BE}} \color[HTML]{000000} 153 & {\cellcolor[HTML]{C5E0DA}} \color[HTML]{000000} 63 & {\cellcolor[HTML]{8BC4B8}} \color[HTML]{000000} 119 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
    % voxel++100-nospeed-nolinger & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 235 & {\cellcolor[HTML]{9ACBC1}} \color[HTML]{000000} 164 &  -  & {\cellcolor[HTML]{B1D6CF}} \color[HTML]{000000} 200 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 3 \\ \hline
    % shortest-path &  -  &  -  &  -  &  -  &  -  \\ \hline
    % object-detector-pure & {\cellcolor[HTML]{AED5CD}} \color[HTML]{000000} 192 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 353 &  -  & {\cellcolor[HTML]{D4E7E3}} \color[HTML]{000000} 273 & {\cellcolor[HTML]{6DB6A7}} \color[HTML]{000000} 4 \\ \hline
    % semantic-entropy & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 321 &  -  &  -  & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 321 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 5 \\ \hline
    % voxel-entropy++100-nospeed & {\cellcolor[HTML]{87C2B6}} \color[HTML]{000000} 110 & {\cellcolor[HTML]{81BFB2}} \color[HTML]{000000} 105 & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 62 & {\cellcolor[HTML]{7FBEB1}} \color[HTML]{000000} 92 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
    % explorer-entropy-8 & {\cellcolor[HTML]{78BBAE}} \color[HTML]{000000} 79 & {\cellcolor[HTML]{7FBEB1}} \color[HTML]{000000} 102 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 83 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 88 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 1 \\ \hline % 7FBEB1



% voxel++025 & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 234 & {\cellcolor[HTML]{D2E6E2}} \color[HTML]{000000} 294 &    -     & {\cellcolor[HTML]{D1E5E1}} \color[HTML]{000000} 264 & {\cellcolor[HTML]{91C7BC}} \color[HTML]{000000} 4 \\ \hline
% voxel++100-nospeed & {\cellcolor[HTML]{98CAC0}} \color[HTML]{000000} 145 & {\cellcolor[HTML]{A4D0C7}} \color[HTML]{000000} 187 & {\cellcolor[HTML]{8EC5BA}} \color[HTML]{000000} 63 & {\cellcolor[HTML]{92C7BC}} \color[HTML]{000000} 132 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline
% voxel++100-nospeed-nolinger & {\cellcolor[HTML]{C1DED8}} \color[HTML]{000000} 233 & {\cellcolor[HTML]{9ACBC1}} \color[HTML]{000000} 164 &    -     & {\cellcolor[HTML]{B1D6CF}} \color[HTML]{000000} 199 & {\cellcolor[HTML]{61B0A0}} \color[HTML]{F1F1F1} 3 \\ \hline
% voxel++100-nospeed-oracle-8-pigeon & {\cellcolor[HTML]{7FBEB1}} \color[HTML]{000000} 91 & {\cellcolor[HTML]{82C0B3}} \color[HTML]{000000} 108 & {\cellcolor[HTML]{CDE4DF}} \color[HTML]{000000} 130 & {\cellcolor[HTML]{87C2B6}} \color[HTML]{000000} 110 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline
% shortest-path & {\cellcolor[HTML]{92C7BC}} \color[HTML]{000000} 132 &    -     &    -     & {\cellcolor[HTML]{92C7BC}} \color[HTML]{000000} 132 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline
% object-detector-pure & {\cellcolor[HTML]{B0D6CE}} \color[HTML]{000000} 197 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 353 &    -     & {\cellcolor[HTML]{D5E8E4}} \color[HTML]{000000} 275 & {\cellcolor[HTML]{95C9BE}} \color[HTML]{000000} 4 \\ \hline
% semantic-entropy & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 321 &    -     &    -     & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 321 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 5 \\ \hline
% voxel-entropy++100-nospeed & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 105 & {\cellcolor[HTML]{8BC4B8}} \color[HTML]{000000} 128 & {\cellcolor[HTML]{9FCEC4}} \color[HTML]{000000} 81 & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 105 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline
% explorer-entropy-8 & {\cellcolor[HTML]{7ABCAF}} \color[HTML]{000000} 82 & {\cellcolor[HTML]{81BFB3}} \color[HTML]{000000} 106 & {\cellcolor[HTML]{9ECDC3}} \color[HTML]{000000} 80 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 89 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 1 \\ \hline
% explorer-entropy-16-nolinger & {\cellcolor[HTML]{AFD5CD}} \color[HTML]{000000} 193 & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 116 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 162 & {\cellcolor[HTML]{9ECDC3}} \color[HTML]{000000} 157 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline
% % explorer-entropy-16-nolinger-noTrainEntropy & {\cellcolor[HTML]{79BBAE}} \color[HTML]{000000} 79 & {\cellcolor[HTML]{8CC5B9}} \color[HTML]{000000} 133 &    -     & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 106 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline


voxel++025 & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 234 & {\cellcolor[HTML]{D2E6E2}} \color[HTML]{000000} 294 &    -     & - & {\cellcolor[HTML]{91C7BC}} \color[HTML]{000000} 4 \\ \hline
voxel++100-nospeed & {\cellcolor[HTML]{98CAC0}} \color[HTML]{000000} 145 & {\cellcolor[HTML]{A4D0C7}} \color[HTML]{000000} 187 & {\cellcolor[HTML]{8EC5BA}} \color[HTML]{000000} 63 & {\cellcolor[HTML]{92C7BC}} \color[HTML]{000000} 132 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
voxel++100-nospeed-nolinger & {\cellcolor[HTML]{C1DED8}} \color[HTML]{000000} 233 & {\cellcolor[HTML]{9ACBC1}} \color[HTML]{000000} 164 &    -     & - & {\cellcolor[HTML]{61B0A0}} \color[HTML]{000000} 3 \\ \hline
voxel++100-nospeed-oracle8-pigeon & {\cellcolor[HTML]{7FBEB1}} \color[HTML]{000000} 91 & {\cellcolor[HTML]{82C0B3}} \color[HTML]{000000} 108 & {\cellcolor[HTML]{CDE4DF}} \color[HTML]{000000} 130 & {\cellcolor[HTML]{87C2B6}} \color[HTML]{000000} 110 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
shortest-path & {\cellcolor[HTML]{92C7BC}} \color[HTML]{000000} 132 &    -     &    -     & - & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
object-detector-pure & {\cellcolor[HTML]{B0D6CE}} \color[HTML]{000000} 197 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 353 &    -     &  - & {\cellcolor[HTML]{95C9BE}} \color[HTML]{000000} 4 \\ \hline
semantic-entropy & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 321 &    -     &    -     & - & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 5 \\ \hline
voxel-entropy++100-nospeed & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 105 & {\cellcolor[HTML]{8BC4B8}} \color[HTML]{000000} 128 & {\cellcolor[HTML]{9FCEC4}} \color[HTML]{000000} 81 & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 105 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
explorer-entropy-8 & {\cellcolor[HTML]{7ABCAF}} \color[HTML]{000000} 82 & {\cellcolor[HTML]{81BFB3}} \color[HTML]{000000} 106 & {\cellcolor[HTML]{9ECDC3}} \color[HTML]{000000} 80 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 89 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 1 \\ \hline
explorer-entropy-16-nolinger & {\cellcolor[HTML]{AFD5CD}} \color[HTML]{000000} 193 & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 116 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 162 & {\cellcolor[HTML]{9ECDC3}} \color[HTML]{000000} 157 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 2 \\ \hline
% explorer-entropy-16-nolinger-noTrainEntropy & {\cellcolor[HTML]{79BBAE}} \color[HTML]{000000} 79 & {\cellcolor[HTML]{8CC5B9}} \color[HTML]{000000} 133 &    -     & {\cellcolor[HTML]{85C1B5}} \color[HTML]{000000} 106 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 2 \\ \hline




    \caption{Overview of the results in the DARPA objects-environment for the best voxel-focused finalist runs. \\ The \textit{Average Time to Goal} is not reported for runs that were not able to scan all 3 goals. }
    \label{tab:results-evaluation-framework}
\end{longtable}
% D7C5AF
The second DARPA environment evaluates the environmnet exploration capabilities of each agent, by measuring the time it takes to discover 10\%, 20\%,..., 100\% of the 3D volume. 
This allows the objective evaluation of how fast and how much actual space the agent discovers.
Table \ref{tab:results-evaluation-framework} shows the results for the best methods tested in the octree-goal task with the Time to Coverage (TTC) relevant percentages of the environment.

\begin{longtable}{|l|c|c|c|c|}                            \hline
    \theadcenteredLeft{Method}            
    & \thead{TTC 10\%} 
    & \thead{TTC 20\%} 
    & \thead{TTC 30\%} 
    % & \thead{TTC 50\%} 
    % & \thead{TTC 70\%} 
    % & \thead{TTC 80\%} 
    % & \thead{TTC 90\%} 
    & \thead{TTC 100\%} 
    \\ \hline
    % blind-octree-explorer-nospeed & {\cellcolor[HTML]{B3D7CF}} \color[HTML]{000000} 247 & {\cellcolor[HTML]{CEE4E0}} \color[HTML]{000000} 589 & {\cellcolor[HTML]{E2EEEB}} \color[HTML]{000000} 755 &  -  \\ \hline
    % octree-16-constrained & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 78 & {\cellcolor[HTML]{95C9BE}} \color[HTML]{000000} 387 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 793 &  -  \\ \hline
    % octree-16-constrained-pigeon & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 69 &  -  &  -  &  -  \\ \hline
    % octree-16-constrained-pigeon-nospeed & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 31 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 88 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 150 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 461 \\ \hline % EBF2F0
    % octree-4 & {\cellcolor[HTML]{DEECE9}} \color[HTML]{000000} 287 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 690 &  -  &  -  \\ \hline
    % octree-4-constrained-pigeon-nospeed & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 298 & {\cellcolor[HTML]{E4EFEC}} \color[HTML]{000000} 664 &  -  &  -  \\ \hline
    % voxel++025 &  -  &  -  &  -  &  -  \\ \hline
    % voxel++100-nospeed &  -  &  -  &  -  &  -  \\ \hline
    % voxel++100-nospeed-nolinger &  -  &  -  &  -  &  -  \\ \hline
    % semantic-curiosity &  -  &  -  &  -  &  -  \\ \hline
    % voxel-entropy++100-nospeed &  -  &  -  &  -  &  -  \\ \hline
    % explorer-entropy-16 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 70 & {\cellcolor[HTML]{6DB6A7}} \color[HTML]{000000} 249 & {\cellcolor[HTML]{74B9AB}} \color[HTML]{000000} 296 &  -  \\ \hline
    % explorer-entropy-8 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 111 & {\cellcolor[HTML]{7DBDB0}} \color[HTML]{000000} 304 & {\cellcolor[HTML]{99CBC1}} \color[HTML]{000000} 450 &  -  \\ \hline

blind-agent-explore-constrained-nospeed & {\cellcolor[HTML]{BADBD4}} \color[HTML]{000000} 256 & {\cellcolor[HTML]{CFE5E0}} \color[HTML]{000000} 591 & {\cellcolor[HTML]{E2EEEB}} \color[HTML]{000000} 755 &    -     \\ \hline
octree-16-constrained & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 83 & {\cellcolor[HTML]{97CABF}} \color[HTML]{000000} 387 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 793 &    -     \\ \hline
octree-16-constrained-pigeon & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 69 &    -     &    -     &    -     \\ \hline
octree-16-constrained-pigeon-nospeed & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 44 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 117 & {\cellcolor[HTML]{5BAD9D}} \color[HTML]{000000} 180 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 461 \\ \hline
octree-4 & {\cellcolor[HTML]{D8E9E5}} \color[HTML]{000000} 287 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 690 &    -     &    -     \\ \hline
octree-4-constrained-pigeon-nospeed & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 307 & {\cellcolor[HTML]{E4EFEC}} \color[HTML]{000000} 665 &    -     &    -     \\ \hline
voxel++025 &    -     &    -     &    -     &    -     \\ \hline
% voxel++100-nospeed &    -     &    -     &    -     &    -     \\ \hline
% voxel++100-nospeed-nolinger &    -     &    -     &    -     &    -     \\ \hline
semantic-curiosity &    -     &    -     &    -     &    -     \\ \hline
voxel-entropy++100-nospeed &    -     &    -     &    -     &    -     \\ \hline
explorer-entropy-16 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 93 & {\cellcolor[HTML]{70B7A9}} \color[HTML]{000000} 249 & {\cellcolor[HTML]{77BAAD}} \color[HTML]{000000} 296 &    -     \\ \hline
% explorer-entropy-16-constrained & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 75 & {\cellcolor[HTML]{77BAAD}} \color[HTML]{000000} 270 & {\cellcolor[HTML]{99CBC1}} \color[HTML]{000000} 443 &    -     \\ \hline
explorer-entropy-16-constrained & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 43 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 90 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 146 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 510 \\ \hline
explorer-entropy-16-constrained-noTrainEntropy & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 139 & {\cellcolor[HTML]{8CC5B9}} \color[HTML]{000000} 349 & {\cellcolor[HTML]{AAD3CA}} \color[HTML]{000000} 512 &    -     \\ \hline
explorer-entropy-8 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 122 & {\cellcolor[HTML]{88C2B6}} \color[HTML]{000000} 332 & {\cellcolor[HTML]{C3DFD9}} \color[HTML]{000000} 622 &    -     \\ \hline
explorer-entropy-8-constrained & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 118 & {\cellcolor[HTML]{76BAAC}} \color[HTML]{000000} 268 & {\cellcolor[HTML]{95C9BE}} \color[HTML]{000000} 422 &    -     \\ \hline

    \caption{Overview of the results in the DARPA exploration-environment for the best octree-focused finalist runs.}
    \label{tab:results-evaluation-framework}
\end{longtable}



\newpage
\section{Further Evaluations}
\subsection{Small Environment Results}\label{chap-4:small-env-results}
The corresponding results for the large environment were presented in Sections \ref{chap:4:results-RQ1} and \ref{chap:4:results-RQ2} respectively. 
This section presents the best performances for the voxel exploration task and the octree exploration task. 

As mentioned before, the small environment has an area of 32 $m^2$ (whereas the large environment counts with 160 $m^2$), which is segmented into 8, 4, 2 octree nodes on the XZ-axis when segmented with node sizes of 4$m^3$, 8$m^3$ and 16$m^3$, respectively.
Since vertical space is not essential for the task at hand (objects are not allocated at different heights), we limited the Y-axis is limited to 4, 2 and 1 nodes, respectively. 
% \textit{Note:} in Unity the Y axis corresponds to the vertical space. 
This is equal to 3D volumes of 256, 32 and 4 nodes, respectively. 
% scale of this environment and how inadequate it is to train exploration tasks. 
Additionally, the agent’s grid sensor is also adjusted to a smaller radius of 8 meters.
The best runs for the voxel-curious behaviors in the small environment are shown in Table \ref{tab:results-small-env-voxel}.

\begin{longtable}{|l|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}            
    & \theadcentered{Episode Length \%}                
    & \theadcentered{Total Objects Scanned} 
    & \theadcentered{Standard  Deviation} 
    % & \thead{F1-score} 
    % & \thead{Octree Leaf \\ Nodes Visited}        
    \\ \hline
    
blind-agent-explore-constrained & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & 0.00 \\ \hline
octree-4 & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & 0.00 \\ \hline
voxel++025 & 100 & {\cellcolor[HTML]{CCE3DF}} \color[HTML]{000000} 4.76 & 1.84 \\ \hline
voxel++050 & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 1.49 & 2.37 \\ \hline
voxel++075 & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 2.62 & 0.47 \\ \hline
voxel++100 & 100 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 9.42 & 0.88 \\ \hline
voxel & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 3.03 & 0.39 \\ \hline
shortest-path & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & 0.00 \\ \hline
object-detector-nospeed & 100 & {\cellcolor[HTML]{67B3A4}} \color[HTML]{000000} 8.71 & 0.01 \\ \hline
object-detector & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.01 & 0.56 \\ \hline
semantic-curiosity & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.16 & 0.12 \\ \hline
semantic-entropy & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & 0.01 \\ \hline
voxel-entropy++050 & 100 & {\cellcolor[HTML]{5AAD9C}} \color[HTML]{000000} 9.19 & 0.00 \\ \hline
voxel-entropy++100 & 100 & {\cellcolor[HTML]{5EAF9E}} \color[HTML]{000000} 9.04 & 0.41 \\ \hline
voxel-entropy-normalized & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & 0.66 \\ \hline
    
    \caption{Overview of the results for the runs in the small environment, with respect to the \textit{Total Objects Scanned} metric.}
    \label{tab:results-small-env-voxel}
\end{longtable}



% name & \%episode\_length & avg\_total\_objects\_scanned & F1\_harmony & \%leafNodesExplored\_norm & Drone/SP: Look Error & Drone/Detections Total Count & Drone/Entropy: RationalizedShannonEntropy \\ \hline
% blind-agent-explore-constrained & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{ACD4CC}} \color[HTML]{000000} 0.50 & 0.35 & 0.00 & 0.00 \\ \hline
% octree-4 & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 1.00 & 0.64 & 0.00 & 0.00 \\ \hline
% shortest-path & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.04 & 0.37 & 0.00 & 0.00 \\ \hline
% semantic-entropy & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.04 & 0.35 & 655758.30 & 0.28 \\ \hline
% voxel-entropy-normalized & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{BADBD4}} \color[HTML]{000000} 0.42 & 0.45 & 312259.79 & 0.10 \\ \hline
% object-detector & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.01 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{E0EDEA}} \color[HTML]{000000} 0.21 & 0.19 & 637355.56 & 0.64 \\ \hline
% semantic-curiosity & 100 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.16 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.02 & {\cellcolor[HTML]{CFE5E0}} \color[HTML]{000000} 0.30 & 0.43 & 606310.02 & 0.30 \\ \hline
% voxel++050 & 100 & {\cellcolor[HTML]{D5E8E4}} \color[HTML]{000000} 1.49 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.11 & {\cellcolor[HTML]{C8E2DC}} \color[HTML]{000000} 0.34 & 0.28 & 0.00 & 0.00 \\ \hline
% voxel++075 & 100 & {\cellcolor[HTML]{C3DFD9}} \color[HTML]{000000} 2.62 & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 0.16 & {\cellcolor[HTML]{C2DFD9}} \color[HTML]{000000} 0.37 & 0.32 & 0.00 & 0.00 \\ \hline
% voxel & 100 & {\cellcolor[HTML]{BDDCD5}} \color[HTML]{000000} 3.03 & {\cellcolor[HTML]{BADAD4}} \color[HTML]{000000} 0.20 & {\cellcolor[HTML]{ACD4CC}} \color[HTML]{000000} 0.50 & 0.20 & 0.00 & 0.00 \\ \hline
% voxel++025 & 100 & {\cellcolor[HTML]{A0CEC5}} \color[HTML]{000000} 4.76 & {\cellcolor[HTML]{99CBC0}} \color[HTML]{000000} 0.23 & {\cellcolor[HTML]{B9DAD3}} \color[HTML]{000000} 0.43 & 0.18 & 0.00 & 0.00 \\ \hline
% object-detector-nospeed & 100 & {\cellcolor[HTML]{60AFA0}} \color[HTML]{000000} 8.71 & {\cellcolor[HTML]{6FB6A8}} \color[HTML]{000000} 0.28 & {\cellcolor[HTML]{BEDCD6}} \color[HTML]{000000} 0.40 & 0.18 & 1282254.18 & 0.53 \\ \hline
% voxel++100 & 100 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 9.42 & {\cellcolor[HTML]{5DAE9D}} \color[HTML]{000000} 0.30 & {\cellcolor[HTML]{B9DAD3}} \color[HTML]{000000} 0.43 & 0.17 & 0.00 & 0.00 \\ \hline
% voxel-entropy++050 & 100 & {\cellcolor[HTML]{59AC9B}} \color[HTML]{000000} 9.19 & {\cellcolor[HTML]{59AC9B}} \color[HTML]{000000} 0.30 & {\cellcolor[HTML]{B7D9D2}} \color[HTML]{000000} 0.44 & 0.16 & 1227545.28 & 0.52 \\ \hline
% voxel-entropy++100 & 100 & {\cellcolor[HTML]{5BAD9C}} \color[HTML]{000000} 9.04 & {\cellcolor[HTML]{55AA99}} \color[HTML]{000000} 0.31 & {\cellcolor[HTML]{B4D8D0}} \color[HTML]{000000} 0.45 & 0.17 & 1142712.42 & 0.49 \\ \hline

% \newpage
The following Table \ref{tab:results-small-env-octree} presents the runs with the best performance in the octree exploration task.
 
\begin{longtable}{|l|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}          
    % & \thead{Episode Length}                
    & \theadcentered{Octree Leaf  \\ Nodes Visited }        
    & \theadcentered{Visited   \\  Volume  ($m^3$)} 
    & \theadcentered{Standard  \\   Deviation} 
    \\ \hline
blind-agent-explore-constrained & 35.63 & {\cellcolor[HTML]{D9E9E6}} \color[HTML]{000000} 142.53 & 0.00 \\ \hline
octree-4 & 71.27 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 285.08 & 0.00 \\ \hline
voxel++025 & 30.52 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 122.10 & 0.01 \\ \hline
voxel++050 & 24.12 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 96.49 & 0.00 \\ \hline
voxel++075 & 26.65 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 106.60 & 0.00 \\ \hline
voxel++100 & 30.42 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 121.67 & 0.00 \\ \hline
voxel & 35.58 & {\cellcolor[HTML]{D9EAE6}} \color[HTML]{000000} 142.31 & 0.00 \\ \hline
shortest-path & 3.16 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 12.64 & 0.00 \\ \hline
object-detector-nospeed & 28.47 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 113.87 & 0.00 \\ \hline
object-detector & 14.62 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 58.48 & 0.00 \\ \hline
semantic-curiosity & 21.56 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 86.24 & 0.00 \\ \hline
semantic-entropy & 2.98 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 11.93 & 0.00 \\ \hline
voxel-entropy++050 & 31.44 & {\cellcolor[HTML]{E9F1EF}} \color[HTML]{000000} 125.76 & 0.01 \\ \hline
voxel-entropy++100 & 32.36 & {\cellcolor[HTML]{E5EFED}} \color[HTML]{000000} 129.43 & 0.00 \\ \hline
voxel-entropy-normalized & 30.02 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 120.08 & 0.00 \\ \hline

    \caption{Overview of the results for the runs in the small environment, with respect to the \textit{Octree Discovery Reward} metric.}
    \label{tab:results-small-env-octree}
\end{longtable}

More information of the results for the the small environment can be found in Figure \ref{appendix:results-small_env_table}






 \newpage
\subsection{Monocular Vision}
This section presents the performance obtained by the panoramic grid sensor and a \textit{55 degrees} wide grid sensor. This latter, narrower, grid sensor represents ordinary cameras that have a smaller field of view \cite{2020_camera_degrees}. Furthermore, we also present the performance results for a wide, circular, voxel scanner that resembles the behavior of an agent that utilizes a smaller radius of the panoramic grid sensor's view. The following Table \ref{tab:results-panoramic} therefore compares the total objects scanned, the look direction, the octree leaf nodes to distinguish key performance differences based on the camera and scanner system. 

\begin{longtable}{|l|c|c|c|c|}                           
    \hline
    \theadcenteredLeft{Method}            
    & \theadcentered{Episode Length \%}                
    & \theadcentered{Total Objects \\ Scanned} 
    & \theadcentered{F1-score} 
    & \theadcentered{Visited  \\ Volume  ($m^3$)} 
    % & \theadcentered{Octree Leaf \\ Nodes Visited \%}
    \\ \hline
    explorer-8 & 100 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 1.96 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 0.35 & {\cellcolor[HTML]{9ACBC1}} \color[HTML]{000000} 151.04 \\ \hline
    ev\_smallcam.explorer-8 & 81 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.00 & {\cellcolor[HTML]{55AA99}} \color[HTML]{F1F1F1} 278.32 \\ \hline
    ev\_bigscanner.explorer-8 & 94 & {\cellcolor[HTML]{B0D6CE}} \color[HTML]{000000} 0.92 & {\cellcolor[HTML]{B8DAD3}} \color[HTML]{000000} 0.28 & {\cellcolor[HTML]{88C2B6}} \color[HTML]{000000} 184.64 \\ \hline
    ev\_bigscanner.explorer-16 & 99 & {\cellcolor[HTML]{B8DAD3}} \color[HTML]{000000} 0.83 & {\cellcolor[HTML]{EBF2F0}} \color[HTML]{000000} 0.23 & {\cellcolor[HTML]{A0CEC5}} \color[HTML]{000000} 139.18 \\ \hline

    \caption{
    Overview of the a subset of the explorer agents with different vision setups: small camera vision (55 degrees), panoramic camera vision (360 degrees) and a panoramic scanner (360 degrees wide and 30 degrees wide north and south).
        }
    \label{tab:results-panoramic}
\end{longtable}




\subsection{PPO vs SAC}

To compare the sample efficiency of PPO and SAC, we trained the best PPO-models using SAC. The following Table \ref{tab:results-SAC} displays the peformance of such models and    of experiments to demonstrate the sample efficiency of PPO. We measure the number of episodes and the number of actions to the state transition in the environment. In addition, we analyze the training speed in our experiments.

\begin{longtable}{|l|c|c|c|}                            \hline
    % \multicolumn{3}{|l|}{\textbf{Voxel-Curiosity}}              \\\hline
    \theadcenteredLeft{Method}            
    & \theadcentered{Episode Length \%}                
    & \theadcentered{Total Objects \\ Scanned} 
    % & \theadcentered{F1-score} 
    & \theadcentered{Visited  \\ Volume  ($m^3$)} 
    % & \theadcentered{Octree Leaf \\ Nodes Visited \%}
    
    \\ \hline
   
 
    {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} explorer-8      & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 86    & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 1.96 & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 151.04 \\ \hline       % & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 0.32 
    {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} explorer-8-sac  & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 63    & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.74 & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 104.04 \\ \hline       % & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.17 
    {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} octree-16-constrained-pigeon        & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 100 & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 0.00  & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 325.61      % & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 0.00    \\ \hline
    {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} octree-16-constrained-pigeon-sac    & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 100   & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.01  & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 123.23 \\ \hline      % & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.00 
    {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} voxel++100-nospeed-nolinger         & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 97    & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 1.62  & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 138.43        % & {\cellcolor[HTML]{B5C3D7}} \color[HTML]{000000} 0.28  \\ \hline
    {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000}  voxel++100-nospeed-nolinger-sac    & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 94    & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.09  & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 23.81 \\ \hline       % & {\cellcolor[HTML]{D7C5AF}} \color[HTML]{000000} 0.03 

    \caption{Overview of a subset of runs trained using PPO and SAC to compare their performance.
    }
    \label{tab:results-SAC}
\end{longtable}








% \subsection{Research Scenarios}
\subsection{Applicable Practical Scenarios} % Future

% \begin{figure}[!ht]
%     \centering
%     \subfigure{\includegraphics[width=0.32\textwidth]{images/unity-environments-stables.png}} 
%     \subfigure{\includegraphics[width=0.32\textwidth]{images/unity-environments-forest.png}} 
%     \subfigure{\includegraphics[width=0.32\textwidth]{images/unity-environments-city.png}}
%     \subfigure{\includegraphics[width=0.32\textwidth]{images/unity-environments-city.png}}
%     \caption{Sample 3D assets for scenario proposals. Taken from \cite{unity-asset-store}.}
%     \label{fig:unity-my-3d-envs}
% \end{figure}

\begin{figure}[!ht]
    \centering
    \subfigure[Dreamscape Scenario.]{\includegraphics[width=0.245\textwidth]{images/unity-env-dreamscape.png} } 
    \subfigure[City Neighborhood.]{\includegraphics[width=0.245\textwidth]{images/unity-env-neighborhood.png}} 
    \subfigure[Snowy Forest.]{\includegraphics[width=0.245\textwidth]{images/unity-env-forest-snowy.png}}
    \subfigure[Summer Forest.]{\includegraphics[width=0.245\textwidth]{images/unity-env-forest.png}}
    \caption{
        Modelled 3D scenarios to present the practical aspect of the proposed methods. 
        \\ 3D models subject to copyright from \textcite{unity-asset-store}.
    }
    \label{fig:unity-my-3d-envs}
\end{figure}

% \begin{figure}[!ht]
%         \centering
%         \includegraphics[width=0.6\textwidth]{images/unity-env-scenarios2.png}
%         \caption{Research Scenarios results.}
%         \label{fig:unity-simple-encoder}
% \end{figure}


Multiple 3D scenes have been collected and setup to demonstrate the applicability of our method in practical real world scenarios. Given the time constraint, deeper demonstrations of these specific use cases are out of scope.
% need to be modelled and constructed to demonstrate the applicability of the learned behavior across a variety of scenarios. 
Figure \ref{fig:unity-my-3d-envs} illustrates the training environment and different environments which were used to demonstrate the octree explorer agent's versatility to multiple environments.

\newpage
Concretely, the 3D environments that were used to test the portability of our approach are: 
\begin{itemize}
    \item \textbf{Dreamscape.} A fantasy forest scene.
    % in reference to the milking robot scenario from our industry partner, Sutter Landtechnik GmbH (SLG).
    \item \textbf{Forest.} An open nature scene with obstacles and a bus that was drove off as part of an accident. It is presented in three weathers: sunny, snowy and snowy overcast.
    \item \textbf{City Neighborhood.} A city scene where fires could be prevented with firefighter drones.
    % that presents buildings and rooms to navigate and explore.
\end{itemize}

Similarly , the voxel-curious agent showed visual agnostic performance to other voxelized objects such as bus and house, which are part of the environments above. 
% Finally, \textit{quidditch} goalposts were also used to test knowledge transferability.


% \subsection{Cross-Scenario Performance}

% The agent showed visual agnostic performance for our agent that was trained on a voxelized bicycle and then tested on a voxelized bus and voxelized house. Moreover, an additional \textit{quidditch} scene was tested, and the agent X showed the best cross-scenario performance. Below are the metrics collected for the cross-scenario performance:

% X

\subsection{Cross-Platform Compatibility}\label{chap:4:cross-platform-compatibility}
This section presents the results of the metrics determined to evaluate the effort of transferring the Unity ML-Agents environment to an OpenAI Gym compatible implementation. We define a compatible implementation as one that is ready to be trained and produce relevant results.

The development metrics are displayed in Table \ref{tab:results-cross-platform}. The agent reward is reported for the training of the \textit{voxel-agent++100} after 20M timesteps. It is negative given that the the voxel rewards are sparse and the movement speed and lingering penalties are dense signals.

\begin{longtable}{|l|c|}                            \hline
    \textbf{Metric}            
    & \thead{Value}  
    \\ \hline
    % portability of the training and the evaluation pipeline

    Lines of code                                       & ~1500                          \\ \hline
    Time required to transition the environment             & ~4h                           \\ \hline
    Time required to integrate to WandB                     & ~20h                       \\ \hline
    Time required to implement resuming of experiments       & ~40h                        \\ \hline
    Time required for other features                        & ~40h                        \\ \hline
    Agent reward after 20M timesteps (baselines)                    & -300                        \\ \hline
    Agent reward after 20M timesteps (mlagents)                    & -374                       \\ \hline
    \caption{Overview of cross-platform effort measurement metrics. }
    \label{tab:results-cross-platform}
\end{longtable}



% \begin{figure}
% \includegraphics[width=1.0\linewidth]{figs/results-on-robots-tutorial/sacs-performance.pdf}
% \caption{Performance comparison of the PPO, SAC, and a vanilla RL agent.}
% \label{fig:sacs-performance}
% \end{figure}





% Table \ref{tab:test-results} provides a brief summary of the results and the general performance of the used algorithms, which are discussed afterwards in more detail.
% \newpage

% \begin{longtable}
% {@{} l c c @{}} \toprule
% \textbf{Method}                     & \textbf{Accuracy}     & \textbf{Standard Deviation}       \\ \midrule
% % PCA                                 & 97\%                  & 0.015                             \\ \midrule
% MAV                                 & \textbf{97\% }                 & \textbf{0.43}                             \\ \midrule
% DOPE                                & 0\%                  & -                             \\ \midrule
% RANSAC                              & 0\%                   & -                             \\ \bottomrule
% \caption{Statistics of tested methods.} \label{tab:test-results}                          \\
% \end{longtable}

% The following Table \ref{tab:DOPE-results} displays the results for the DOPE algorithm. DOPE uses FAT formatted data sets, which are generated using NDDS, in Unreal Engine 4. These data sets are characterized for being synthetic photorealistic images. The data set variants presented below are optimized by modifying the parameters in data set used, such as:
% % The variants used include changes in: 
% the realism degree in the materials used for the object textures, the usage of rotation in the focus object, and the usage of obstructive objects. Aditionally, all data sets include five different photorealistic scenes: beach, studio, temple, meadow and zen garden. Surprisingly none of the data sets were realistic enough to close the reality gap, which reflected in DOPE not outputting any predictions.



% \begin{longtable}{|l|c||c|}                            \hline
% \multicolumn{3}{|l|}{\textbf{Deep Object Pose}}              \\\hline
% \textbf{Dataset}            & \textbf{Size}  & \textbf{Functional}            \\ \hline
% NDDS Photorealistic (base)       & 260k      & No                             \\ \hline
% NDDS with Rotation          & 80k       & No                             \\ \hline
% NDDS Small                  & 20k       & No                             \\ \hline
% \caption{Overview of the best DOPE results for the respective dataset variations.} \label{tab:DOPE-results}
% \end{longtable}


% The results for the RANSAC algorithm are shown in Table \ref{tab:ransac-results}. The skimage implementation was used for both RANSAC and direct ORB matching. The variants presented were surprinsingly not succesful at matching X. It is suspected that RANSAC and ORB matching are not the best approach for identifying simple texture objects such as the cow teats. 
% Figure \ref{fig:ransac-results} illustrates the suspicion and the behavior of RANSAC on both the RGB and the depth images. RANSAC was tested by varying the ORB number of keypoints, the ORB threshold and RANSAC's residual threshold as well as adding a denoising step.  


% \begin{longtable}{|c|c|c|c||c|}                            \hline
% \multicolumn{5}{|l|}{\textbf{RANSAC / ORB Matching}}              \\\hline
% \textbf{ORB \#keypoints} & \textbf{ORB threshold} & \textbf{Residual Threshold} & \textbf{Denoising}       & \textbf{Functional}      \\ \hline
%         20      & 0.08      & N/A (ORB matching)       & No     &  No               \\ \hline
%         200     & 0.08      & N/A (ORB matching)       & No     &  No               \\ \hline
%         200     & 0.02      & 0.5       & No     &  No               \\ \hline
%         200     & 0.02      & 0.5       & Yes    &  No               \\ \hline
%         200     & 0.02      & 0.9       & No     &  No               \\ \hline
%         200     & 0.02      & 0.9       & Yes    &  No               \\ \hline
%         200     & 0.08      & 0.5       & No     &  No               \\ \hline
%         200     & 0.08      & 0.5       & Yes    &  No               \\ \hline
%         200     & 0.08      & 0.9       & No     &  No               \\ \hline
%         200     & 0.08      & 0.9       & Yes    &  No               \\ \hline
% \caption{Overview of the best MAV results for the respective offset-averaging mechanisms combinations.} \label{tab:ransac-results}                          
% \end{longtable}


%  \begin{figure}[h]
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cow_ransac.png}
%         \caption{RANSAC's behavior on the cow data set.}
%         \label{fig:ransac-results}
%     \end{figure}
    
% The following table 
% % \ref{tab:mav-results} displays 
% presents the results for the "MAV" algorithm. The optimizations presented are a combination of the offset and the averaging method.

% \begin{longtable}{|l|l||c|c|c|}                                              \hline
% \multicolumn{5}{|l|}{\textbf{MAV}}                                                       \\\hline
% \textbf{Offset}         & \textbf{Averaging Method}   
% & \textbf{Average Error}  & \textbf{Standard Deviation}  & \textbf{Execution Time}                 \\ \hline
% Fixed                   & Single Point                & 1.13            & 2.8              & 0.26 - 1.5 secs   \\ \hline
% Calculated              & Single Point                & 1.77            & 3.3              & 0.26 - 1.5 secs   \\ \hline
% Fixed                   & Average: 1/3rd              & \textbf{0.67}   & \textbf{2.4}     & 0.26 - 1.5 secs                     \\ \hline
% Calculated              & Average: 1/3rd              & 1.54            & 2.93             & 0.26 - 1.5 secs    \\ \hline
% Fixed                   & Average: 1/10th             & 0.96            & 2.55             & 0.26 - 1.5 secs     \\ \hline
% Calculated              & Average: 1/10th             & 1.51            & 2.87             & 0.26 - 1.5 secs    \\ \hline
% \caption{Overview of the best MAV results for the respective offset-averaging mechanisms combinations.} \label{tab:mav-results}                          
% \end{longtable}

% \subsubsection{Research Question 2}

% The second research question tackles the evaluation of the pose estimation of cow teats.

% \subsubsection{Quality Ranking of Predictions}


\section{Deliverables}
The following deliverables will be handed in with this master thesis:
\begin{itemize}
    \item This work produced three types of exploration-capable agents: environment-focused, object-focused and mixed-focused.
    The environment-focused agent is able to explore twice as many leaf nodes as the non-explorative models (71 versus 35 average leaf nodes per episode). This means that the average performance of the explorative agent explores 88\% of the small environment. 
    
    \item  The object-focused agent is able to scan at least 2 objects per episode on average. This translates to a scanning speed of 2500 time steps per object.
    
    \item Finally, the mixed exploration agent is able to keep up with the 2 objects per episode performance and explore an average 41 leaf nodes per episode, which covers 51\% of the environment, outperforming the 43\% coverage of object-focused models.
   
   \item A set of baselines are also handed in, used to analyze the performance of traditional methods for exploration (random actions, shortest path) and other state-of-the-art-inspired methods (object detection maximization, semantic curiosity, semantic entropy).
   
    \item The trained models for our proposed method in ONNX formats, including all other variants for voxel and octree exploration and an out-of-the-box Unity-ready reinforcement learning environment capable of reproducing the experiments and results.

    \item For future research, a set of Unity scenes that demonstrate the versatility of the reinforcement learning agent. These scenes further allow the creation of future benchmarks for other synthetic data models and use cases, which are not limited to machine learning approaches.
\end{itemize}
