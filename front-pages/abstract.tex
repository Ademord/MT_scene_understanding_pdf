\chapter*{Abstract}
\setheader{Abstract}
%  TAKEN FROM MY GOOGLE DOCS

The large and still increasing popularity of deep learning, along with the growing availability of 3D labeled datasets has been setting the stage to the continuous development of new algorithms in scene understanding and autonomous systems. Where traditional approaches to navigation depend on task subdivisions and map awareness, newer approaches take on the problem of navigation from the perspective of model-free solutions with partial observability, given that challenging real life scenarios, such as rescue missions and dynamic scenes, are unknown environments.

In this thesis, we propose an embodied agent to tackle the problem of object exploration given partial observability in an unknown environment by exploiting octrees for the efficient navigation of 3D scenes. Furthermore, given the necessity to incorporate the temporal dimension in visual object recognition tasks, we propose extrinsic rewards for the scanning of voxelized objects with a reinforcement learning agent in order to cover various trajectories around an object of interest, therefore reducing the uncertainty of such objects and their characteristics.
We also take into account the level of entropy in a simulated Unity environment to adjust the behavior of our agent on-the-fly, improving on the exploratory performance of current methods in active vision. 
Our results outperform our Unity implementations of previous classical and geometric approaches and improve upon current state-of-the-art exploration methods that are motivated by coverage maximization and semantic curiosity. We achieve better exploratory performance by at least a factor of two in the scanning of objects and cover 8\% more of the environment in comparison to our baselines.

Furthermore, by using octrees, voxels and panoramic vision, our method is able to adapt to new environments without changes in its behavior or fine-tuning, bridging the gap between synthetic data and real data for the exploration of 3D environments, where the data distribution plays a key role given the commonly seen noise, outliers and missing data in RGB-D sensors.
Finally, given the increasing amount of algorithms, newer and extensible benchmarks are needed for testing more sophisticated challenges that are representative of the real world. Motivated by recent works in the Unity 3D engine and the ML-Agents plugin, we demonstrate the applicability our approach in three 3D environments, test its performance in two environments inspired by the DARPA Subterranean Challenge and aim to further motivate the creation of new benchmarks, custom-made testing environments, exploration methods, and the reproducibility and extensibility of research results.

Our approach aims to serve as a baseline for computer vision methods that incorporate the temporal dimension for increased certainty about objects, in tasks such as synthetic data generation, rescue missions, autonomous driving, exploration and navigation, point-to-goal tasks, etc. The code base for our method can be found at \url{https://github.com/Ademord/ma-unity}. All Unity 3D Assets are protected by copyright.


% The large and still increasing popularity of deep learning, along with the growing availability of 3D labeled datasets has been setting the stage to the continuous development of new algorithms in scene understanding and exploration of unknown environments. However, these works continue to build modular and hierarchical architectures, engineer complex features in the pre-processing stage and lack reproducibility.

% Current methods use either LiDAR data, RGBD data or point clouds to reconstruct top-down 2D maps for exploration in traditional benchmarks or simplistic or limited 3D environments. These methods are computationally and memory-wise expensive and depend heavily on the training data. We tackle the problem of exploration in an unknown environment by exploiting octrees for efficient navigation of 3D scenes, where we also define the uninformativeness in an unknown environment through voxelized objects and semantic entropy.

% The key contribution of this thesis is a novel voxel- and octree-based exploration method that builds upon model-free reinforcement learning to enable visual-agnostic exploration of environments and objects, while also taking into account the inconsistencies in the temporal class density present in the environment. 
% We demonstrate that our method outperforms Unity implementations of previous classical and geometric approaches and improves upon current state-of-the-art exploration methods that are motivated by coverage maximization and semantic curiosity.

% Moreover, by using voxels for exhaustive exploration of objects and grid sensors with panoramic coverage, our method bridges the gap between synthetic data and real data for the exploration of 3D environments, where the data distribution plays a key role in the performance of transfer learning techniques, enabling the agent to adapt to new environments without changes in its behavior.

% Finally, with an ever increasing amount of algorithms, traditional benchmarks become uninformative and allow room for the creation of newer ones capable of testing more sophisticated challenges, representative of the real world. Motivated by recent works in the Unity 3D engine, we contribute three 3D environments that can be extended for the creation of new benchmarks, testing of new exploration methods and for a variety of other tasks such as synthetic data generation, autonomous driving, exploration, navigation, point-to-goal tasks, etc. The code base for our method can be found at \url{https://github.com/Ademord/ma-unity}. All Unity 3D Assets are protected by copyright.


% We demonstrate that our method outperforms previous classical and geometric approaches and improves upon current state-of-the-art exploration methods that are motivated by coverage maximization and semantic curiosity.


% Computer vision has been a field of study since the 1960s, and over the past few years a lot of challenges, such as 2D object recognition are now considered solved problems. Nevertheless, default uncertainty in all environments is the basis of all vision problems, such as detection and recognition.
% The goal of this work is to analyze diverse exploration policies using reinforcement learning, and find an applicable solution for unknown 3D environments. 
% This work will contribute to the computer vision challenges encountered by the project "Melkroboter" project at the ZHAW.